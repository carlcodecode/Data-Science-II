{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1fjnIza1OTRxPgYa2D9q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlcodecode/Data-Science-II/blob/main/NNFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovKIqnOgeYRm",
        "outputId": "a1809ef8-c569-412c-f222-7b1aa3208463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.5807],\n",
            "        [ 4.4269],\n",
            "        [ 1.1115],\n",
            "        [ 1.0987],\n",
            "        [-0.1980],\n",
            "        [-1.0085],\n",
            "        [ 4.2295],\n",
            "        [ 0.8105],\n",
            "        [ 0.2932],\n",
            "        [ 0.4800]])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#this is our batch of data\n",
        "N = 10\n",
        "#data point will have one input and one output feature\n",
        "D_in = 1\n",
        "D_out = 1\n",
        "\n",
        "X = torch.randn(N, D_in)\n",
        "\n",
        "#create our \"true labels\" for training\n",
        "W_true = torch.tensor([[2.0]])\n",
        "b_true = torch.tensor(1.0)\n",
        "y_true = X @ W_true + b_true + torch.randn(N, D_out) * 0.1 #add some noise\n",
        "\n",
        "print(y_true[:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize our parameters with random values\n",
        "#shapes must be correct\n",
        "\n",
        "W = torch.randn(D_in, D_out, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(f\"Initial weight: {W}\")\n",
        "print(f\"Initial b: {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu54e92xfp74",
        "outputId": "db736885-58ac-49cc-f374-27e6b7d1dd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weight: tensor([[-0.4030]], requires_grad=True)\n",
            "Initial b: tensor([-0.8332], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forward pass\n",
        "y_hat = X @ W + b\n",
        "print(y_hat)\n",
        "print(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUKG0jqlgR2z",
        "outputId": "cad6275f-4cbe-45ff-9b8b-118a9e2afca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5480],\n",
            "        [-1.5673],\n",
            "        [-0.9110],\n",
            "        [-0.8544],\n",
            "        [-0.6130],\n",
            "        [-0.4199],\n",
            "        [-1.4806],\n",
            "        [-0.8187],\n",
            "        [-0.6813],\n",
            "        [-0.7301]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 4.5807],\n",
            "        [ 4.4269],\n",
            "        [ 1.1115],\n",
            "        [ 1.0987],\n",
            "        [-0.1980],\n",
            "        [-1.0085],\n",
            "        [ 4.2295],\n",
            "        [ 0.8105],\n",
            "        [ 0.2932],\n",
            "        [ 0.4800]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate loss\n",
        "error = (y_hat - y_true)\n",
        "squared_error = error ** 2\n",
        "loss = squared_error.mean()\n",
        "print(f\"Our loss: {loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Q12CJOgduJ",
        "outputId": "db8f6826-11ff-4c30-dc0f-6183e3979527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our loss: 11.959053039550781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward pass + compute gradient using autograd\n",
        "# calculate gradient of loss w.r.t. W\n",
        "# calculate gradient of loss w.r.t. b\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(f\"Grad for W: {W.grad}\")\n",
        "print(f\"Grad for b: {b.grad}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvRjGMW1gsxH",
        "outputId": "c27e5b37-fffb-4a67-8729-34dc894bdbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grad for W: tensor([[-6.2200]])\n",
            "Grad for b: tensor([-5.0898])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update W and b\n",
        "W = W - 0.1*W.grad\n",
        "b = b - 0.1*b.grad\n",
        "\n",
        "y_hat = X @ W + b\n",
        "\n",
        "print(y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYByys3xh3Xi",
        "outputId": "7e1464f6-8aee-4a13-f1fb-183d94585052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0643],\n",
            "        [ 0.0748],\n",
            "        [-0.2819],\n",
            "        [-0.3126],\n",
            "        [-0.4439],\n",
            "        [-0.5488],\n",
            "        [ 0.0276],\n",
            "        [-0.3321],\n",
            "        [-0.4067],\n",
            "        [-0.3802]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate loss\n",
        "error = (y_hat - y_true)\n",
        "squared_error = error ** 2\n",
        "loss = squared_error.mean()\n",
        "print(f\"Our loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11VmE6ssicn1",
        "outputId": "1d04aeaf-dea3-4b87-facb-d79cf0408ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our loss: 6.373559474945068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is our batch of data\n",
        "N = 10\n",
        "#data point will have one input and one output feature\n",
        "D_in = 1\n",
        "D_out = 1\n",
        "\n",
        "X = torch.randn(N, D_in)\n",
        "\n",
        "#create our \"true labels\" for training\n",
        "W_true = torch.tensor([[2.0]])\n",
        "b_true = torch.tensor(1.0)\n",
        "y_true = X @ W_true + b_true + torch.randn(N, D_out) * 0.1 #add some noise\n",
        "\n",
        "print(y_true[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAxFNsUiiwua",
        "outputId": "e2c8da7d-7139-47f9-cd4e-9ee80bf42e7b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3054],\n",
            "        [ 1.1211],\n",
            "        [ 1.7664],\n",
            "        [-2.1983],\n",
            "        [ 2.0278],\n",
            "        [ 1.4555],\n",
            "        [ 2.0974],\n",
            "        [ 4.1976],\n",
            "        [ 2.7756],\n",
            "        [ 1.1257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training process\n",
        "\n",
        "#hyper parameters\n",
        "lr = 0.01\n",
        "epochs = 100\n",
        "\n",
        "W = torch.randn(D_in, D_out, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #forward pass\n",
        "  y_hat = X @ W + b\n",
        "  #compute loss\n",
        "  loss=torch.mean((y_hat-y_true)**2)\n",
        "  #backward pass + compute gradients\n",
        "  loss.backward()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch {epoch:02d}: Loss={loss.item():.4f}, W={W.item():.4f}, b={b.item():.4f}\")\n",
        "\n",
        "  #update params -> no_grad because we don't need to track the updates\n",
        "  with torch.no_grad():\n",
        "    W -= lr * W.grad\n",
        "    b -= lr * b.grad\n",
        "\n",
        "  #zero the gradients because we don't want to sum previous\n",
        "  W.grad.zero_()\n",
        "  b.grad.zero_()\n",
        "\n",
        "print(f\"Final Parameters: W={W.item():.4f}, b={b.item():.3f}\")\n",
        "print(f\"True Parameters: W={W_true.item()}, b={b_true.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DDGSRR22jkO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87237d49-baaa-4a34-95b5-1dd8e1f71dcb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00: Loss=17.1762, W=-0.6931, b=-1.9579\n",
            "Epoch 10: Loss=11.0412, W=-0.2280, b=-1.3243\n",
            "Epoch 20: Loss=7.1109, W=0.1522, b=-0.8230\n",
            "Epoch 30: Loss=4.5901, W=0.4636, b=-0.4270\n",
            "Epoch 40: Loss=2.9712, W=0.7193, b=-0.1145\n",
            "Epoch 50: Loss=1.9298, W=0.9296, b=0.1317\n",
            "Epoch 60: Loss=1.2585, W=1.1030, b=0.3254\n",
            "Epoch 70: Loss=0.8248, W=1.2464, b=0.4774\n",
            "Epoch 80: Loss=0.5437, W=1.3652, b=0.5966\n",
            "Epoch 90: Loss=0.3610, W=1.4638, b=0.6897\n",
            "Final Parameters: W=1.5460, b=0.762\n",
            "True Parameters: W=2.0, b=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9d9N1-_iWCvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}